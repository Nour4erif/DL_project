{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff290c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        Load the data:\n",
    "            - 14,034 images to train the network.\n",
    "            - 3,000 images to evaluate how accurately the network learned to classify images.\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = ['seg_train/', 'seg_test/']\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b936ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each image is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,\n",
    "                    'test': test_counts}, \n",
    "             index=class_names\n",
    "            ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(train_counts,\n",
    "        explode=(0, 0, 0, 0, 0, 0) , \n",
    "        labels=class_names,\n",
    "        autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_images = train_images / 255.0 \n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "def display_random_image(class_names, images, labels):\n",
    "    \"\"\"\n",
    "        Display a random image from the images array and its correspond label from the labels array.\n",
    "    \"\"\"\n",
    "    \n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_image(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930977ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 25 images from the training set directly with a loop to get a better view\n",
    "\n",
    "def display_examples(class_names, images, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "        Display 25 images from the images array with its corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a39ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450c5ef",
   "metadata": {},
   "source": [
    "### Simple Model Creation\n",
    "\n",
    "Steps are:\n",
    "\n",
    "1- Build the model,\n",
    "2- Compile the model,\n",
    "3- Train / fit the data to the model,\n",
    "4- Evaluate the model on the testing set,\n",
    "5- Carry out an error analysis of our model.\n",
    "\n",
    "We can build an easy model composed of different layers such as:\n",
    "\n",
    "-> Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n",
    "-> MaxPooling2D: The images get half sized.\n",
    "-> Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n",
    "-> Relu : given a value x, returns max(x, 0).\n",
    "-> Softmax: 6 neurons, probability that the image belongs to one of the classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e8445",
   "metadata": {},
   "source": [
    "### Then, we can compile it with some parameters such as:\n",
    "\n",
    " Optimizer: adam = RMSProp + Momentum. What is Momentum and RMSProp ?\n",
    " Momentum = takes into account past gradient to have a better update.\n",
    " RMSProp = exponentially weighted average of the squares of past gradients.\n",
    " Loss function: we use sparse categorical crossentropy for classification, each images belongs to one class only\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4315a",
   "metadata": {},
   "source": [
    "We will fit the model to the data from the training set.\n",
    "The neural network will learn by itself the pattern in order to distinguish each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ff29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ed6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cedb2d0",
   "metadata": {},
   "source": [
    "We will evaluate the model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e46e3",
   "metadata": {},
   "source": [
    "As we see that we achieve 0.78 accuracy on the testing test. We got a slight underfitting \n",
    "\n",
    "Let's see how the classifier is doing on random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8610b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)     # Vector of probabilities\n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n",
    "\n",
    "display_random_image(class_names, test_images, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473cb4d",
   "metadata": {},
   "source": [
    "# Error analysis ..\n",
    "We can try to understand on which kind of images the classifier has trouble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53079a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n",
    "    \"\"\"\n",
    "        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n",
    "    \"\"\"\n",
    "    BOO = (test_labels == pred_labels)\n",
    "    mislabeled_indices = np.where(BOO == 0)\n",
    "    mislabeled_images = test_images[mislabeled_indices]\n",
    "    mislabeled_labels = pred_labels[mislabeled_indices]\n",
    "\n",
    "    title = \"Some examples of mislabeled images by the classifier:\"\n",
    "    display_examples(class_names,  mislabeled_images, mislabeled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mislabeled_images(class_names, test_images, test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65249f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_labels, pred_labels)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True, \n",
    "           annot_kws={\"size\": 10}, \n",
    "           xticklabels=class_names, \n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d608e00",
   "metadata": {},
   "source": [
    "Conclusion: The classifier has trouble with 2 kinds of images.\n",
    "It has trouble with street and buildings. Well, it can be understandable as as there are buildings in the street. It has also trouble with sea, glacier and moutain as well. It is hard for me to fully distinguish them. However, it can detects forest very accurately!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092b2dc",
   "metadata": {},
   "source": [
    "## Feature extraction with VGG ImageNet\n",
    "We can extract features from VGG16.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ac4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c380406",
   "metadata": {},
   "source": [
    "## Visualize the features through PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, x, y, z = train_features.shape\n",
    "n_test, x, y, z = test_features.shape\n",
    "numFeatures = x * y * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components = 2)\n",
    "\n",
    "X = train_features.reshape((n_train, x*y*z))\n",
    "pca.fit(X)\n",
    "\n",
    "C = pca.transform(X) # Représentation des individus dans les nouveaux axe\n",
    "C1 = C[:,0]\n",
    "C2 = C[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figures\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.title(\"PCA Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b4ee9",
   "metadata": {},
   "source": [
    "We can identifying clusters thanks to this PCA. The clusters correspond more or less to the labels.\n",
    "\n",
    "We see that glacier and mountain points are very close to each other, as VGG sees them as very similar.\n",
    "\n",
    "We see that there is no distinction between building and street."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6ad0b",
   "metadata": {},
   "source": [
    "## Training on top of VGG\n",
    "Let's train a simple one-layer Neural Network on the features extracted from VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb673c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bff160",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f04967",
   "metadata": {},
   "source": [
    "We should get approximately 0.844 accuracy (+0.1 accuracy) over the simple ConvNet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ebfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model2.evaluate(test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340197e",
   "metadata": {},
   "source": [
    "## Ensemble Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64590a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1997)\n",
    "# Number of estimators\n",
    "n_estimators = 10\n",
    "# Proporition of samples to use to train each training\n",
    "max_samples = 0.8\n",
    "\n",
    "max_samples *= n_train\n",
    "max_samples = int(max_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124475d",
   "metadata": {},
   "source": [
    "We define n_estimators Neural Networks.\n",
    "\n",
    "Each Neural Network will be trained on random subsets of the training dataset. Each subset contains max_samples samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cacf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "random = np.random.randint(50, 100, size = n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    \n",
    "    # Model\n",
    "    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "                                # One layer with random size\n",
    "                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "                                ])\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Store model\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    # Train each model on a bag of the training data\n",
    "    train_idx = np.random.choice(len(train_features), size = max_samples)\n",
    "    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=10, validation_split = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96131bc",
   "metadata": {},
   "source": [
    "We should improve our result as we have a lower variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1483565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212a0ce",
   "metadata": {},
   "source": [
    "## Fine Tuning VGG ImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a78b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfe241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n",
    "\n",
    "model2 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "input_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\n",
    "layer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n",
    "# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n",
    "\n",
    "x = layer_input\n",
    "for layer in model2.layers[-4::1]:\n",
    "    x = layer(x)\n",
    "    \n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100,activation='relu')(x)\n",
    "x = Dense(6,activation='softmax')(x)\n",
    "\n",
    "# create the model\n",
    "new_model = Model(layer_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_model.fit(train_features, train_labels, batch_size=128, epochs=10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca498d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = new_model.predict(test_features)    \n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c692e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744088d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a167b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
